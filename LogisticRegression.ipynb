{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d12620-30c7-4bcc-b96b-cc8888f3611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi=False\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import sklearn.preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Utils import load_data, print_memory_usage\n",
    "\n",
    "path_train = \"Data/Train.csv\"\n",
    "path_val = \"Data/Validation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ebd92-67ef-4004-947f-0c8a897a0655",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb9f19-451b-4b9c-9652-7b0b4ed57123",
   "metadata": {},
   "source": [
    "The first model I want to try is a simple logistic regression model.\n",
    "Lets start with a simple test model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5dcb3-d300-40fc-97db-aacd53999b54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variable Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32b5a8-6094-41b1-88ab-1bf331c38ddd",
   "metadata": {},
   "source": [
    "One question here is how to choose a proper encoding for some of the variables.\n",
    "\n",
    "1. Hour of the day: One approach is convert it into a cyclic variable, and another is to use fixed \"binned\" time intervales like morning, midday, evening. We could also convert each hour into a category, but this does not make much sense.\n",
    "2. Numerical Features should be scaled to be comparable? -> Only relevant for gradient optimization, but might want to scale to 0 mean? Also affects regularization, which is on by default -> SHOULD STANDARDIZE, YES (also mentioned in elements of statistical learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca855e74-6940-449a-95c5-06dd7cfc344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_to_coordinate(h):\n",
    "    xh = np.sin(2*np.pi*(h)/24)\n",
    "    yh = np.cos(2*np.pi*(h)/24)\n",
    "    return xh,yh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1714ce3b-501a-4042-8942-9336003d0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_tod(data,dummies=False):\n",
    "    #Categroies based on plots in Analysis Notebook\n",
    "    hours = data[\"starttime\"].dt.hour \n",
    "    bins=[-1,6,10,15,24] \n",
    "    names=[0,1,2,3]\n",
    "    tod = pd.cut(hours,bins,labels=names)\n",
    "    tod = tod.astype(\"int64\")\n",
    "    if dummies:\n",
    "        tod = pd.get_dummies(tod,prefix=\"tod\",drop_first=True)\n",
    "    return tod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23dba9c1-f0f3-496e-888b-6417c9cdaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_train,Y_train, X_val,Y_val):\n",
    "    #print some summary statistics about the model\n",
    "    #TODO: Add uncertainty estimates about these\n",
    "    Y_train_pred = model.predict(X_train)\n",
    "    training_acc = accuracy_score(Y_train,Y_train_pred)\n",
    "    print(f\"Training accuracy: {training_acc}\")\n",
    "    Y_val_pred = model.predict(X_val)\n",
    "    val_acc = accuracy_score(Y_val,Y_val_pred)\n",
    "    print(f\"Val accuracy: {val_acc}\")\n",
    "    confusion_train = confusion_matrix(Y_train,Y_train_pred,normalize=\"true\")\n",
    "    print(f\"Training confusion: \")\n",
    "    print(confusion_train)\n",
    "    confusion_val = confusion_matrix(Y_val,Y_val_pred,normalize=\"true\")\n",
    "    print(f\"Validation confusion: \")\n",
    "    print(confusion_val)\n",
    "    coefficients = pd.Series([clf.intercept_[0]]+list(clf.coef_[0]),index=[\"intercept\"]+list(X.columns))\n",
    "    print(\"Coefficients: \")\n",
    "    print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eab3d5-fb6d-4de1-aa82-443ac08908f7",
   "metadata": {},
   "source": [
    "Note that we cannot encode the station id as a one-hot vector because it takes too much memory.\n",
    "Instead I will just encode whether the station is one of the top 10 customer stations or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9de07e7-a10b-4415-8f3f-dbb208331cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_stations(data,k=20):\n",
    "    grouped = data_train.groupby(\"usertype\")[\"start station id\"].value_counts()\n",
    "    return grouped[\"Customer\"][0:k].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "281bc8d2-2597-4279-b249-494b26e9f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_stations_by_customercount(X,data):\n",
    "    grouped = data.groupby(\"usertype\")[\"start station id\"].value_counts()\n",
    "    counts = grouped[\"Customer\"]\n",
    "    X[\"start customercount\"] = data[\"start station id\"].map(counts).fillna(0).astype(int)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a5098-b382-48e2-8c3f-e8a5b66d9293",
   "metadata": {},
   "source": [
    "TODO: Proper data preparation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb0c8e-43c6-4357-95c3-626b694abab5",
   "metadata": {},
   "source": [
    "TODO: Take log of some features that span multiple orders of magnitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc465846-7ac6-4f9c-96d9-353519319d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now I omit information about station ids\n",
    "def preprocess(data,scaler=None): #TODO: Use pipelines instead\n",
    "    numerical = [\"haversine distance\",\"tripduration\",\"speed\", \"start customercount\"]\n",
    "    features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"roundtrip\", \"speed\"]\n",
    "    unused = [c for c in data.columns if c not in features]\n",
    "    label=\"usertype\"\n",
    "    X = data.drop(columns=unused)\n",
    "    Y = data[label].copy()\n",
    "    \n",
    "    tod=categorize_tod(data,dummies=True)\n",
    "    X = pd.concat([X,tod],axis=1,copy=False)\n",
    "    interaction = tod.mul(X[\"business day\"],axis=0)\n",
    "    interaction.columns = [\"business x \" + c for c in tod.columns]\n",
    "    X = pd.concat([X,interaction],axis=1,copy=False)\n",
    "    \n",
    "    #Try encoding start station as categorical\n",
    "    #topstations = top_stations(data,k=20)\n",
    "    #X[\"topstation\"] = data[\"start station id\"].isin(topstations)\n",
    "    \n",
    "    #Try encoding station by customer count\n",
    "    X = encode_stations_by_customercount(X,data)\n",
    "        \n",
    "    #X[\"birth year\"] = data[\"birth year\"]-data[\"birth year\"].min() #scale to smaller integer range\n",
    "    #data[\"gender_male\"] = data[\"gender\"] == 1\n",
    "    #data[\"gender_unknown\"] = data[\"gender\"] == 0\n",
    "    Y=(Y==\"Customer\")\n",
    "    if not scaler:\n",
    "        scaler = sklearn.preprocessing.MinMaxScaler() #MinMaxScaler or StandardScaler does not seem to matter. MinMaxScaler has advantage of preserving speed = 0 values for roundtrips\n",
    "        scaler = scaler.fit(X[numerical])\n",
    "    X[numerical] = scaler.transform(X[numerical])  \n",
    "    return X,Y,scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7190844-b56d-48ef-a3ab-d92b601a1d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = load_data(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61c8386d-af3f-42bc-a107-edcafddc1129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X,Y,scaler = preprocess(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40b247c2-55fa-42b5-8d7e-53ce86fdf38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8905596285361598"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = DummyClassifier()\n",
    "baseline = baseline.fit(X,Y)\n",
    "acc_base = baseline.score(X,Y)\n",
    "acc_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "403cfdda-9b77-4c21-9a9e-e34840c7d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=300) #Might make sense to use balanced class weights here\n",
    "clf=clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538c768-6c7c-4d99-a105-c20c9aaae900",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = load_data(path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e5ae710-5a8b-4374-a103-ef05b75684e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val,scaler = preprocess(data_val,scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c612866-6ed8-4a37-aef4-067a9452c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9012529724987639\n",
      "Val accuracy: 0.8951307947455558\n",
      "Training confusion: \n",
      "[[0.98221255 0.01778745]\n",
      " [0.75754713 0.24245287]]\n",
      "Validation confusion: \n",
      "[[0.9909919  0.0090081 ]\n",
      " [0.88141488 0.11858512]]\n",
      "Coefficients: \n",
      "intercept              -0.459020\n",
      "tripduration            2.048347\n",
      "roundtrip              -1.098812\n",
      "haversine distance      7.207567\n",
      "business day           -0.685669\n",
      "speed                 -15.702991\n",
      "summer                  0.624983\n",
      "tod_1                   0.082217\n",
      "tod_2                   0.377071\n",
      "tod_3                   0.239407\n",
      "business x tod_1       -0.486538\n",
      "business x tod_2        0.133096\n",
      "business x tod_3       -0.298165\n",
      "start customercount     2.733849\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(clf,X,Y,X_val,Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bf673-e54a-4700-afd3-e279bf60f8cc",
   "metadata": {},
   "source": [
    "Notes: By using gender=unknown, gender=male categorical features one can easily get about 94% training accuracy, and about 98% on subscribers. Using classes = balanced gives 79% accuracy overall, but like 82% on customers instead of 20% for unbalanced.\n",
    "\n",
    "Scaling data with min-max scaler seems to have no effect\n",
    "Using categorical tod encoding does not seem much different from using ordinal encoding or hours, at least if we dont use interactions.\n",
    "Adding interaction terms between tod and business day does not help much.\n",
    "\n",
    "Adding top_20_customer_start_station as label increases accuracy from about 89.5 % to 90%.\n",
    "Instead using customer counts of each start_station as a feature gives 90% training but only 89.5% validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea2f67c7-2f0f-4dfd-995d-5e56746b2188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894888232649087"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00636ae6-0b89-43e7-b4d8-e346571d0e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98162453, 0.01837547],\n",
       "       [0.80773977, 0.19226023]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_val)\n",
    "confusion_matrix(Y_val,Y_pred,normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac70cd4-7df3-4f00-bef7-7baa53742934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901187982192281"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.score(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd9198-763e-49a3-abf9-ec56521c38cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
