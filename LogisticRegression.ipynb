{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a2bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi=False\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Utils import print_memory_usage, frequency_encode_stations, evaluate_model, train, validate, load_data \n",
    "\n",
    "path_train = \"Data/Train.parquet\"\n",
    "path_val = \"Data/Validation.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ab474",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f32840",
   "metadata": {},
   "source": [
    "The first model we try is a simple logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f53701",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variable Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31798a8",
   "metadata": {},
   "source": [
    "The first question is how to choose a proper encoding for the features:\n",
    "\n",
    "1. Hour of the day: One approach is convert it into a cyclic variable. Another is to use fixed \"binned\" time intervales like morning, midday, evening.\n",
    "2. Station ID: Since an ordinal encoding does not make sense, we will try a frequency encoding.\n",
    "2. Numerical Features should be scaled to be comparable, since we use weight decay which depends on the scale on the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15995f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_coefficients(model,feature_names):\n",
    "    coefficients = pd.Series([model.intercept_[0]]+list(model.coef_[0]),index=[\"intercept\"]+list(feature_names))\n",
    "    print(\"Coefficients: \")\n",
    "    print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f55404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_to_coordinate(data,features):\n",
    "    h = data[\"starttime\"].dt.hour\n",
    "    xh = np.sin(2*np.pi*(h)/24)\n",
    "    yh = np.cos(2*np.pi*(h)/24)\n",
    "    data[\"xh\"] = xh\n",
    "    data[\"yh\"] = yh\n",
    "    features = features + [\"xh\",\"yh\"]\n",
    "    return data,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8628619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_tod(data,features,add_interactions=False):\n",
    "    #Categories based on plots in Analysis Notebook\n",
    "    hours = data[\"starttime\"].dt.hour \n",
    "    bins=[-1,6,10,15,24] \n",
    "    names=[0,1,2,3]\n",
    "    tod = pd.cut(hours,bins,labels=names)\n",
    "    tod = pd.get_dummies(tod,prefix=\"tod\",drop_first=True)\n",
    "    new=[tod]\n",
    "    features = features + list(tod.columns)\n",
    "    if add_interactions:\n",
    "        interaction = tod.mul(data[\"business day\"],axis=0)\n",
    "        interaction.columns = [\"business x \" + c for c in tod.columns]\n",
    "        new += [interaction]\n",
    "        features = features + list(interaction.columns)\n",
    "    data = data.join(new) \n",
    "    return data,features\n",
    "def categorize_tod_interactions(data,features):\n",
    "    \"\"\"Wrapper for convenience.\"\"\"\n",
    "    return categorize_tod(data,features,add_interactions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c48d95",
   "metadata": {},
   "source": [
    "Now lets try logistic regression with different features and preprocessings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff33dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hours(data,features):\n",
    "    features = features + [\"hour\"]\n",
    "    data[\"hour\"] = data[\"starttime\"].dt.hour\n",
    "    return data,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b559fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Accuracy: 0.8941807341401965\n",
      "Confusion: \n",
      "[[0.9817782  0.0182218 ]\n",
      " [0.81854074 0.18145926]]\n",
      "MCC: 0.2732489467624145\n",
      "Validation: \n",
      "Accuracy: 0.8942341632136787\n",
      "Confusion: \n",
      "[[0.98194031 0.01805969]\n",
      " [0.81980536 0.18019464]]\n",
      "MCC: 0.2724035976893507\n"
     ]
    }
   ],
   "source": [
    "pre = add_hours\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\"]\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8985f",
   "metadata": {},
   "source": [
    "Categorizing tod instead slightly improves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51069a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Accuracy: 0.895168003048048\n",
      "Confusion: \n",
      "[[0.98156348 0.01843652]\n",
      " [0.8077737  0.1922263 ]]\n",
      "MCC: 0.28574764216388404\n",
      "Validation: \n",
      "Accuracy: 0.8951586467528946\n",
      "Confusion: \n",
      "[[0.98161271 0.01838729]\n",
      " [0.80868733 0.19131267]]\n",
      "MCC: 0.2848225615211647\n"
     ]
    }
   ],
   "source": [
    "pre = categorize_tod\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\"]\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48464c96-5c81-417a-ba6f-a395385f6f74",
   "metadata": {},
   "source": [
    "Alternatively, we can try a cyclic encoding, but the performance does not change much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c13b6d4-d04a-44e9-ad4c-fd77de1db63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Accuracy: 0.8951237382751984\n",
      "Confusion: \n",
      "[[0.98170481 0.01829519]\n",
      " [0.80932799 0.19067201]]\n",
      "MCC: 0.28450710970717225\n",
      "Validation: \n",
      "Accuracy: 0.8951780975204277\n",
      "Confusion: \n",
      "[[0.98180349 0.01819651]\n",
      " [0.8100627  0.1899373 ]]\n",
      "MCC: 0.28404669400888083\n"
     ]
    }
   ],
   "source": [
    "pre = hour_to_coordinate\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\"]\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f0cc6-cb4f-4554-b1d7-7f63788e58fc",
   "metadata": {},
   "source": [
    "We can also add an interaction term between tod and business day, since we have seen that the distribution of subscribers over the day depends strongly on whether its a business day or holiday. However, the effect on model performance is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a965150-9a7b-40bb-9f4d-ce7494fd89d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Accuracy: 0.8953738092132513\n",
      "Confusion: \n",
      "[[0.98178976 0.01821024]\n",
      " [0.8077345  0.1922655 ]]\n",
      "MCC: 0.28691115450030363\n",
      "Validation: \n",
      "Accuracy: 0.8953239782769251\n",
      "Confusion: \n",
      "[[0.98179514 0.01820486]\n",
      " [0.80866118 0.19133882]]\n",
      "MCC: 0.2857544379373309\n"
     ]
    }
   ],
   "source": [
    "pre = categorize_tod_interactions\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\"]\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd8624-706f-4811-b345-acb2ec26580d",
   "metadata": {},
   "source": [
    "Lets also add station ids. We try it once without any encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7efda0e-2c86-4343-854f-936313fff747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8907051986151061\n",
      "Confusion: \n",
      "[[0.99827718 0.00172282]\n",
      " [0.98453545 0.01546455]]\n",
      "MCC: 0.07564733748703922\n",
      "Validation: \n",
      "Accuracy: 0.8907370296275235\n",
      "Confusion: \n",
      "[[0.99829263 0.00170737]\n",
      " [0.98490229 0.01509771]]\n",
      "MCC: 0.0743261364445043\n"
     ]
    }
   ],
   "source": [
    "pre = categorize_tod_interactions\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\", \"start station id\", \"end station id\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\"]\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e877e78-6929-4545-9bff-e60dcb8fe7f9",
   "metadata": {},
   "source": [
    "Using unencoded station ids does not make sense for logistic regression because the ids do not reflect an ordering.\n",
    "Using one-hot encoding might work, but requires a lot of memory and introduces many variables (one per station ids, so about 800). Therefore, we will use a frequency encoding, mapping the stations to a corresponding fraction of customers / subscribers in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e6bd89-17a4-46e0-8a6c-1fc476912193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_1(data,features):\n",
    "    data, features = categorize_tod(data,features,add_interactions=True)\n",
    "    data, features = frequency_encode_stations(data,features)\n",
    "    return data,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b43e05f-5122-4526-9c44-5b261ccb62f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Accuracy: 0.90196339653685\n",
      "Confusion: \n",
      "[[0.9819877  0.0180123 ]\n",
      " [0.74914037 0.25085963]]\n",
      "MCC: 0.35639811832864116\n",
      "Validation: \n",
      "Accuracy: 0.9019698478778354\n",
      "Confusion: \n",
      "[[0.98198784 0.01801216]\n",
      " [0.74947835 0.25052165]]\n",
      "MCC: 0.355995401986027\n"
     ]
    }
   ],
   "source": [
    "pre = preprocess_1\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\", \"start customer freq\",\"start subscriber freq\",\"stop customer freq\",\"stop subscriber freq\"]\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373de39-54ef-4648-a80d-a6e2203a474b",
   "metadata": {},
   "source": [
    "This improves the model alot.\n",
    "Two more things I want to try: Using balanced labels, and adding start-end station interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e2666e7-19ed-4f21-8a2f-b2d568af801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Accuracy: 0.7933540912949856\n",
      "Confusion: \n",
      "[[0.79473631 0.20526369]\n",
      " [0.2178921  0.7821079 ]]\n",
      "MCC: 0.40641754869466673\n",
      "Validation: \n",
      "Accuracy: 0.7927966942848497\n",
      "Confusion: \n",
      "[[0.79400006 0.20599994]\n",
      " [0.21700022 0.78299978]]\n",
      "MCC: 0.40608697111151654\n"
     ]
    }
   ],
   "source": [
    "pre = preprocess_1\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\", \"start customer freq\",\"start subscriber freq\",\"stop customer freq\",\"stop subscriber freq\"]\n",
    "clf = LogisticRegression(max_iter=300,class_weight=\"balanced\")\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd42e32-221f-4fff-9d53-bcee91c1bb70",
   "metadata": {},
   "source": [
    "And now with start-end station interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13dbe4fa-4162-4dc2-bbbb-7edb6487ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_2(data,features):\n",
    "    data, features = categorize_tod(data,features,add_interactions=True)\n",
    "    data, features = frequency_encode_stations(data,features)\n",
    "    data[\"customer start x stop\"] = data[\"start customer freq\"].mul(data[\"stop customer freq\"],axis=0)\n",
    "    data[\"subscriber start x stop\"] = data[\"start subscriber freq\"].mul(data[\"stop subscriber freq\"],axis=0)\n",
    "    features = features+[\"customer start x stop\", \"subscriber start x stop\"]\n",
    "    return data,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0332cf-e92b-437f-a676-1e3a0c752ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Accuracy: 0.7953510832927155\n",
      "Confusion: \n",
      "[[0.79695971 0.20304029]\n",
      " [0.21773726 0.78226274]]\n",
      "MCC: 0.4090453628418705\n",
      "Validation: \n",
      "Accuracy: 0.7946691167006006\n",
      "Confusion: \n",
      "[[0.79614744 0.20385256]\n",
      " [0.21736629 0.78263371]]\n",
      "MCC: 0.40828140331115814\n"
     ]
    }
   ],
   "source": [
    "pre = preprocess_2\n",
    "features=[\"tripduration\", \"summer\",\"business day\", \"haversine distance\", \"is_roundtrip\", \"speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = [\"tripduration\",\"haversine distance\", \"speed\", \"start customer freq\",\"start subscriber freq\",\"stop customer freq\",\"stop subscriber freq\", \"customer start x stop\", \"subscriber start x stop\"]\n",
    "clf = LogisticRegression(max_iter=300,class_weight=\"balanced\")\n",
    "print(\"Training: \")\n",
    "clf,feature_names = train(path_train,clf,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler = True)\n",
    "print(\"Validation: \")\n",
    "validate(clf,path_val,features,preprocess=pre,scaler=scaler,features_to_scale=features_to_scale,fit_scaler=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268a084-9875-4257-afb3-b8adb881a812",
   "metadata": {},
   "source": [
    "Finally, lets have a look at the model coefficients to see which features are most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac5cc62-78fd-4f4c-b2b9-52926d128ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "intercept                   1.830502\n",
      "tripduration                4.468506\n",
      "is_roundtrip               -1.225583\n",
      "haversine distance          6.581761\n",
      "speed                     -14.932430\n",
      "business day               -0.698999\n",
      "summer                      0.661630\n",
      "tod_1                      -0.036107\n",
      "tod_2                       0.203431\n",
      "tod_3                       0.121509\n",
      "business x tod_1           -0.512030\n",
      "business x tod_2            0.123386\n",
      "business x tod_3           -0.267613\n",
      "start customer freq         3.717062\n",
      "start subscriber freq      -1.707202\n",
      "stop customer freq          3.717062\n",
      "stop subscriber freq       -1.707202\n",
      "customer start x stop      -5.545453\n",
      "subscriber start x stop     1.808514\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print_model_coefficients(clf,feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
